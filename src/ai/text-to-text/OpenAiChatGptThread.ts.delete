import spaceTrim from 'spacetrim';
import { getSupabaseForServer } from '../../utils/supabase/getSupabaseForServer';
import { string_model_name, uuid } from '../../utils/typeAliases';
import { getOpenaiForServer } from './getOpenaiForServer';
import { Prompt } from './prompt-templates/lib/src/classes/Prompt';
import { ChatThread } from './prompt-templates/lib/src/execution/ChatThread';

/**
 * Create conversation with ChatGPT
 *
 * Note: This class is aviable only on the server
 */
export class OpenAiChatGptThread implements ChatThread {
    /**
     * Starts a new ChatThread conversation
     *
     * @param prompt text to send to the OpenAI API
     * @returns response from the OpenAI API wrapped in ChatThread
     */
    public static async ask(prompt: Prompt, clientId: uuid /* <-[ðŸŒº] */): Promise<OpenAiChatGptThread> {
        return /* not await */ OpenAiChatGptThread.create(null, prompt, clientId);
    }

    /**
     * Makes a prompt to the OpenAI API and returns a response wrapped in ChatThread
     * @private Utility method within the class ChatThread
     */
    private static async create(
        parentChatThread: null | OpenAiChatGptThread,
        prompt: Prompt,
        clientId: uuid /* <-[ðŸŒº] */,
    ): Promise<OpenAiChatGptThread> {
        const mark = `ask-gpt-${parentChatThread ? parentChatThread.chatSize : 1}`;

        const promptAt = new Date();
        performance.mark(`${mark}-start`);
        const model = 'gpt-3.5-turbo'; /* <- TODO: To global config */
        const modelSettings = { model };
        const completion = await getOpenaiForServer().chat.completions.create({
            ...modelSettings,
            messages: [
                {
                    role: 'user',
                    content: prompt.toString(),
                },
            ],
        });
        performance.mark(`${mark}-end`);
        const answerAt = new Date();
        // console.log(performance.measure(mark, `${mark}-start`, `${mark}-end`));

        if (!completion.choices[0]) {
            // [5]
            throw new Error(`No choises from OpenAPI`);
        }

        if (completion.choices.length > 1) {
            // TODO: This should be maybe only warning
            // [5]
            throw new Error(`More than one choise from OpenAPI`);
        }

        // Display response message to user
        const response = completion.choices[0].message.content;

        if (!response) {
            // [5]
            throw new Error(`No response message from OpenAPI`);
        }

        /**/
        // TODO: [ðŸ§ ] Make config value DEBUG_LOG_GPT
        console.info(
            spaceTrim(
                (block) => `
                    ===========================[ Chat: ]===
                    [ðŸ§‘] ${block(prompt.toString())}
                    [ðŸ¤–] ${block(response)}
                    ---
                    Executed in ${block(
                        performance.measure(mark, `${mark}-start`, `${mark}-end`).duration.toString(),
                    )}ms 
                    ${completion.usage?.total_tokens} tokens used
                    ===========================[ /Chat ]===
                `,
            ),
        );
        /**/

        // Note: We do not want to wait for the insert to the database
        /* not await */ getSupabaseForServer()
            .from('Prompt')
            .insert(
                {
                    // Metadata
                    type: 'CHAT',
                    clientId,
                    metadata: {
                        /* TODO: Is metadata needed? */
                    },

                    // Model
                    model,
                    modelSettings,

                    // Prompt
                    prompt: prompt,
                    systemMessage: null,
                    // TODO: !!previousExternalId: parentChatThread ? parentChatThread. : null,
                    promptAt,

                    // Response
                    answer: response,
                    externalId: null,
                    fullCompletion: completion,
                    answerAt,

                    // <- TODO: [ðŸ’¹] There should be link to wallpaper site which is the prompt for (to analyze cost per wallpaper)
                    // <- TODO: [ðŸŽ ] There should be a prompt template+template version+template language version (to A/B test performance of prompts)
                    // <- TODO: Use here more precise performance measure
                } as any /* <- TODO: [ðŸ–] It is working in runtime BUT for some strange reason it invokes typescript error */,
            )
            .then((insertResult) => {
                // TODO: !! Util isInsertSuccessfull
                // console.log('ChatThread', { insertResult });
            });

        return new OpenAiChatGptThread(
            clientId,
            parentChatThread,
            completion.model as string_model_name,
            prompt,
            response,
        );
    }

    private constructor(
        public readonly clientId: uuid /* <-[ðŸŒº] */,
        public readonly parent: null | OpenAiChatGptThread,
        public readonly model: string_model_name,
        public readonly prompt: Prompt,
        public readonly response: string,
    ) {}

    /**
     * Continues in ChatThread conversation
     *
     * @param prompt text to send to the OpenAI API
     * @returns response from the OpenAI API wrapped in ChatThread
     */
    public async ask(prompt: Prompt): Promise<OpenAiChatGptThread> {
        return /* not await */ OpenAiChatGptThread.create(this, prompt, this.clientId);
    }

    public get chatSize(): number {
        return this.parent ? this.parent.chatSize + 1 : 1;
    }
}

/**
 * TODO: !!!last Go through this file and remove it
 * TODO: [ðŸ§ ] Rename ChatThread -> OpenAiChatGptThread
 * TODO: [ðŸ§­] !! This should be under Make @ptp/openai-tools
 * TODO: [âœ”] Check ModelRequirements here
 * TODO: [ðŸ§ ] Wording: response or answer?
 * TODO: [ðŸšž] DRY ChatThread+completeWithGpt
 * TODO: [5] Log also failed prompt as in completeWithGpt
 * TODO: Make IAskOptions
 */
